{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4주차 과제.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glorykim999910/aiacademy/blob/master/4%EC%A3%BC%EC%B0%A8%EA%B3%BC%EC%A0%9C(%EA%B9%80%EC%83%81%EB%AF%BC).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxkL6PjwsI6L",
        "colab_type": "text"
      },
      "source": [
        "# 4주차 과제\n",
        "- 용어 정리\n",
        "- 딥러닝 강의 클론 코딩\n",
        "- 딥러닝 순전파 & 역전파 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixEtDe6_uGgI",
        "colab_type": "text"
      },
      "source": [
        "## 1. 용어 정리\n",
        "\n",
        "다음 제시된 단어의 정의(설명)를 정리하여 작성 하세요.\n",
        "\n",
        "* 2문장 이상 작성 해 주세요. \n",
        "* 주제(단어)와 크게 벗어나지만 않는다면 정답처리 됩니다.\n",
        "* 강의 뿐 아니라 기타 레퍼런스를 참고하여 작성하셔도 됩니다. (기타 레퍼런스를 참고하신 경우, 해당 레퍼런스를 정리하여 하단에 작성해 주세요.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfwat8eurKZ",
        "colab_type": "text"
      },
      "source": [
        "__(예시)__\n",
        "### 심층 신경망\n",
        ": 입력층과 출력층 사이에 여러 개의 은닉층들로 이뤄진 인공신경망이다. 심층 신경망은 일반적으로 인공신경망과 마찬가지로 복잡한 비선형 관계들을 모델링 할 수 있다. 신층신경망의 목적은 분류 및 수치예측을 하기 위함이고 이미지 트레이닝이나 문자인식과 같은 분야에서 매우 유용하게 쓰이고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8YJNKG_v65A",
        "colab_type": "text"
      },
      "source": [
        "### MCP 뉴런\n",
        ": 1943년 맥컬록과 월터 피츠가 제안한 뉴런과 시냅스의 개념을 적용한 이론이다. 수상돌기(입력층)에서 복수의 화학적 신호들을 받아 신경세포체(은닉층)을 통해 통합하고 축삭돌기(출력층)를 전기신호로 변경하는 뇌의 구조에 신경세포와 뉴런의 신호를 이진 출력을 내도록 간단한 논리회로로 표현하였다.\n",
        "\n",
        "\n",
        "### 퍼셉트론\n",
        ": 1957년 프랭크 로젠블렛은 MCP 뉴런기반이론을 기반으로 퍼셉트론 심층신경망 학습개념을 발표하였다. 퍼셉트론은 입력과 임계치를 포함한 활성화함수, 출력으로 구성되며, 이때 입력값의 누적이 임계치보다 크면 1을 반환하고, 0을 반환하는 이진결과를 출력값으로 갖는다(+1, -1).\n",
        "또한 자동으로 최적의 가중치를 학습하는 알고리즘 제안이후, 가중치는 뉴런의 출력신호를 낼지말지 결정하는 입력특성에 곱하는 계수를 뜻하며, 단층퍼셉트론에서 발생하는 XOR문제는 다층퍼셉트론으로 해결하였으며, 차후의 지도학습의 분류개념에서 지대한 영향을 주었다.\n",
        "\n",
        "* 출처\n",
        "  - 블로그 : 기계학습 01.인공뉴런과 퍼셉트론의 원리 첫번째_딥러닝의 조상 퍼셉트론의 이해[https://yamerong.tistory.com/43]\n",
        "  - 블로그 : 초기 머신러닝의 간단한 역사[https://thebook.io/007022/ch02/01/]\n",
        "\n",
        "\n",
        "### 역전파\n",
        "다층퍼셉트론에서 파라미터 갯수가 증가하여, 최적의 가중치와 편향을 학습하기에 어려움이 발생하는 문제를 해결하는 알고리즘 및 방법론이다. 즉 손실함수가 최소값일때 파라미터를 찾아 올바른 학습결과를 도출하는 것이며, 손실함수의 최소값과 가중치를 효율적으로 찾기 위해 뉴런의 가중치를 거꾸로(출력층->입력층) 적용한다. 현재출력값을 기대출력값으로 변경하고, 오차를 구한뒤 바로 이전의 값이 큰 쪽의 가중치와 편향을 크게 조정한다.\n",
        "역전파의 단점은 기울기소멸이다. 시그모이드(미분최대치 0.3 이므로 계속곱하면 0에 가까워짐)와 소프트맥스(출력값으로부터 확률벡터를 얻으며, 노드의 미분출력값 0< 범위 <1)는 최종출력을 결정하는데 합리적인 선택은 가능하나 출력값이 1보다 작으므로 오차의 기울기가 작아져 기울기가 소실되어 가중치 조정이 이루어지지 않는다. 제프리힌튼 교수가  ReLu 활성화함수를 제시하여, 입력이 음수면 0, 입력이 양수면 양수값 그대로 출력하여 어느정도 기울기소실문제에 대해 해결하였다.\n",
        "\n",
        "\n",
        "### 강화학습\n",
        ": 지도학습처럼 정답이 존재하지않고, 비지도학습처럼 데이터가 존재하지 않는다. 에이전트와 환경이 상호작용하고, 보상을 최대하는 방향으로 학습을 수행하여 \n",
        "에이전트의 다수의 시행착오를 통해 명확한 문제를 해결한다. 사람으로부터 학습을 받는 것이 아니라, 환경으로부터 보상받아 학습한다는 점이 지도학습과 차이점이 있다.\n",
        "보상을 최대화하는 의사결정전략, 순차적인 행동을 알아나가는 기법이다.\n",
        "  \n",
        "  강화학습의 동작순서는 다음과 같다.\n",
        "  1. 정의된 에이전트가 환경의 현재상태를 관찰\n",
        "  2. 관찰한 결과를 기반으로 행동함\n",
        "  3. 환겨으이 상태가 변화되면, 정의된 에이전트는 보상이 수여됨\n",
        "  4. 보상을 기반으로 정의된 에이전트는 더 많은 보상을 얻는 방향으로 학습을 실시함\n",
        "  \n",
        "  보상을 최대화하는 행동을 수행하는 방법은 활용과 탐험 사이의 균형을 적절히 맞추는 방법의 대표적인 사례는 MDP가 존재한다.\n",
        "  활용은 현재까지의 경험 중 현 상태에서 가장 최대의 보상을 얻을 수 있는 행동을 수행하는 것이며, 탐험은 다양한 경험을 쌓기 위해 새로운 시도를 하는 것이다.\n",
        "\n",
        "* 출처\n",
        "  - 블로그 : 머신러닝 - 강화학습[http://tcpschool.com/deep2018/deep2018_machine_reinforcement]\n",
        "\n",
        "\n",
        "\n",
        "### 과적합\n",
        ": 모델이 학습 데이터셋(훈련) 안에서 일정 수준 이상의 예측 정확도를 보이나, 새로운 데이터셋에 적용하면 예측 정확도가 떨어지는 현상이다. 즉 훈련 데이터셋에서 최적화가 되어 있으므로, 완전히 새로운 데이터에 적용하면 분류나 회귀문제에 가장 최적의 오판단을 할 가능성이 발생한다. 딥러닝에서 과적합은 층이 매우 많거나, 변수가 복잡할때 발생하기도 하고, 테스트셋과 학습 셋이 중복될 때 발생하기도 한다. 따라서 과적합을 방지하기 위해서는 훈련 데이터셋(0.7)과 평가 데이터셋(0.3)을 완전히 구분한 뒤 동시에 평가를 병행하면서 진행되어야 한다. 훈련 데이터셋으로 모델을 생성한 뒤, 평가 데이터셋을 모델에 적용하여, 정확도를 확인하면서 예측율을 측정할 수 있다.  \n",
        "\n",
        "* 출처\n",
        "  - 도서 : 과적합 이해하기[모두의 딥러닝 개정2판, 길벗출판사, 조태호 지음]\n",
        "\n",
        "\n",
        "### 차원의 저주\n",
        ": 데이터 학습을 위해 차원이 증가하면서 학습데이터의 수가 차원의 수보다 적어져 성능이 저하되는 현상이다. 즉 차원이 증가할 수록 모델성능이 저하되고, 개별 차원 내 학습할 데이터가 적어지는(sparse) 현상이 발생한다.\n",
        "관측치 수가 변수의 수보다 많아지면 발생한다.\n",
        "KNN알고리즘은 차원이 커질수록 이웃간의 거리가 점점 멀어지므로, 차원이 커지면, 데이터를 정제하거나 다른 알고리즘을 사용해야 한다.\n",
        "해결책 : 차원을 축소시키거나 데이터를 많이 획득한다.\n",
        "\n",
        "* 출처\n",
        "  - 블로그 : 차원의 저주[https://datapedia.tistory.com/15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zfFXLCy6jD",
        "colab_type": "text"
      },
      "source": [
        "## 2. 딥러닝 강의 클론 코딩\n",
        "\n",
        "####__퍼셉트론 구조 구현하기__ \n",
        "딥러닝 강의(__딥러닝 원리[1] 3:15 ~ 5:15 부분__)를 보고 코드를 따라 치며 출력 결과를 만드세요.\n",
        " \n",
        "\n",
        "* 하나의 코드셀에 해당 코드를 한번에 다 적어서 실행해주세요 (__그렇게 하지 않을 경우, 아래 이미지와 같은 출력값이 나오지 않을 수 있습니다__)\n",
        "\n",
        "*__주의!__ 실제로 코딩해서 출력해보면 강의에 나온 출력 결과와 다르게 나옵니다!!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8KYmK1Y5pmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "419a3435-568e-4a7f-86dc-af1a271e8b9c"
      },
      "source": [
        "import tensorflow as tf # tensorflow 임포트, 알리아스 tf\n",
        "tf.compat.v1.set_random_seed(2020) # tf.compat.v1의 set_random_seed(2020) 무작위 랜덤추출\n",
        "\n",
        "# 1. x = 1, y = 0 일때 error 및 예측결과 도출\n",
        "\n",
        "x = 1 \n",
        "y = 0\n",
        "w = tf.random.normal([1],0,1) # 무작위 랜덤 가중치\n",
        "\n",
        "import math # math함수 임포트\n",
        "def sigmoid(x): # 시그모이드함수 정의\n",
        "  return 1/(1+math.exp(-x))\n",
        "\n",
        "output = sigmoid(x*w) # 시그모이드값 변수 output에 대입\n",
        "print(output) # output 출력\n",
        "\n",
        "for i in range(1000): # 1000회 반복\n",
        "  output = sigmoid(x*w) # 시그모이드값 변수 output에 대입\n",
        "  error = y - output # 기대출력 - 실제출력\n",
        "  w = w+x*0.1*error # 경사하강법 : 가중치 + x*학습률*error\n",
        "\n",
        "  if i % 100 == 99: # i가 100으로 나뉘서 나머지가 99인 경우만 출력\n",
        "    print(\"학습횟수 \", i, \"Error\", error, \"예측결과\", output)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습횟수  99 Error -0.10010598284299604 예측결과 0.10010598284299604\n",
            "학습횟수  199 Error -0.05178399422833116 예측결과 0.05178399422833116\n",
            "학습횟수  299 Error -0.034590451977903586 예측결과 0.034590451977903586\n",
            "학습횟수  399 Error -0.02588962752851373 예측결과 0.02588962752851373\n",
            "학습횟수  499 Error -0.020658699939863617 예측결과 0.020658699939863617\n",
            "학습횟수  599 Error -0.017174253993457355 예측결과 0.017174253993457355\n",
            "학습횟수  699 Error -0.014689506449480992 예측결과 0.014689506449480992\n",
            "학습횟수  799 Error -0.012829497265431342 예측결과 0.012829497265431342\n",
            "학습횟수  899 Error -0.011385568271837804 예측결과 0.011385568271837804\n",
            "학습횟수  999 Error -0.010232493309882492 예측결과 0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_zgychQ-M1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "5524827c-7036-485d-99fd-9a8d3e349e31"
      },
      "source": [
        "\n",
        "# 2. x = 0 , y = 1일때 # x = 1, y = 0 일때 error 및 예측결과 도출\n",
        "# 가중치이상현상발생!!  \n",
        "x = 0\n",
        "y = 1\n",
        "w = tf.random.normal([1],0,1) # 무작위 랜덤 가중치\n",
        "b = tf.random.normal([1],0,1) # 무작위 랜덤 편향\n",
        "for i in range(1000): \n",
        "  output = sigmoid(x*w) # 시그모이드 출력값 변수 output에 대입\n",
        "  error = y - output # 기대출력값 - 실제출력값을 변수 error에 대입\n",
        "  w = w+x*0.1*error # 경사하강법 : 가중치 + x*학습률*error \n",
        " \n",
        "  # 입력값이 0이므로 가중치조절에 의미가 없어짐 => 해결 : 편향값 설정\n",
        "   \n",
        "  if i % 100 == 99: \n",
        "    print(\"학습횟수 \", i, \"Error\", error, \"예측결과\", output)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습횟수  99 Error 0.5 예측결과 0.5\n",
            "학습횟수  199 Error 0.5 예측결과 0.5\n",
            "학습횟수  299 Error 0.5 예측결과 0.5\n",
            "학습횟수  399 Error 0.5 예측결과 0.5\n",
            "학습횟수  499 Error 0.5 예측결과 0.5\n",
            "학습횟수  599 Error 0.5 예측결과 0.5\n",
            "학습횟수  699 Error 0.5 예측결과 0.5\n",
            "학습횟수  799 Error 0.5 예측결과 0.5\n",
            "학습횟수  899 Error 0.5 예측결과 0.5\n",
            "학습횟수  999 Error 0.5 예측결과 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsLuwzoD9KNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "f77e90ff-b9e8-4941-b01e-ee17b2cd3a3e"
      },
      "source": [
        "# 3. x = 0 , y = 1일때 # x = 1, y = 0 일때 error 및 예측결과 도출\n",
        "# 가중치이상현상발생!! ==> 편향으로 해결\n",
        "\n",
        "x = 0\n",
        "y = 1\n",
        "w = tf.random.normal([1],0,1) # 무작위 랜덤 가중치\n",
        "b = tf.random.normal([1],0,1) # 무작위 랜덤 편향\n",
        "for i in range(1000): \n",
        "  output = sigmoid(x*w+1*b) # 시그모이드 출력값 변수 output에 대입\n",
        "  error = y - output # 기대출력값 - 실제출력값을 변수 error에 대입\n",
        "  w = w+x*0.1*error # 경사하강법 : 가중치 + x*학습률*error \n",
        " \n",
        "  # 입력값이 0이므로 가중치조절에 의미가 없어짐 => 해결 : 편향값 설정\n",
        "  b = b+1*0.1*error # 편향값 \n",
        "\n",
        "  if i % 100 == 99: \n",
        "    print(\"학습횟수 \", i, \"Error\", error, \"예측결과\", output)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습횟수  99 Error 0.1029023890447952 예측결과 0.8970976109552048\n",
            "학습횟수  199 Error 0.052561826664552225 예측결과 0.9474381733354478\n",
            "학습횟수  299 Error 0.03494193728929851 예측결과 0.9650580627107015\n",
            "학습횟수  399 Error 0.02608775473104219 예측결과 0.9739122452689578\n",
            "학습횟수  499 Error 0.020785289260269568 예측결과 0.9792147107397304\n",
            "학습횟수  599 Error 0.017261946235979875 예측결과 0.9827380537640201\n",
            "학습횟수  699 Error 0.014753774297972089 예측결과 0.9852462257020279\n",
            "학습횟수  799 Error 0.01287858489963467 예측결과 0.9871214151003653\n",
            "학습횟수  899 Error 0.011424277362518054 예측결과 0.988575722637482\n",
            "학습횟수  999 Error 0.010263781336492528 예측결과 0.9897362186635075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcc5mzI9oZ7r",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0cceeed0-0235-4b0f-af88-0b8c377d5b4b%2F_2020-06-09__9.35.23.png?table=block&id=88fd8912-9356-49a4-9fda-a1a63fe96ea9&width=2870&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0HVRk8fOom",
        "colab_type": "text"
      },
      "source": [
        "## 3. 딥러닝 순전파 & 역전파 계산\n",
        "\n",
        "딥러닝 강의(__딥러닝 원리[2] 0:55 ~ 4:32 부분__)에 나오는 순전파 & 역전파 계산에 대한 문제 입니다.\n",
        "\n",
        "해당 영상과 다음 이미지를 참고하여 다음 2가지 물음에 답하세요.\n",
        "\n",
        "\n",
        "(1) 학습률이 0.2 일 경우 출력층의 노드값\n",
        "\n",
        "(2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpwPFWhOUzww",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff54dfd45-92ec-44ae-9616-6949d2484a45%2F_2020-06-10__5.22.03.png?table=block&id=ee05da89-3ceb-4ad9-a2d3-c9f68d24d1d9&width=3580&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2OVY7w5U3CI",
        "colab_type": "text"
      },
      "source": [
        "## (1) 학습률이 0.2 일 경우 출력층의 노드값 : 1.76\n",
        "* ![오차 역전파문제](https://content/오차역전파문제.PNG)\n",
        "\n",
        "* 풀이순서\n",
        "1. 출력층결과와 지도데이터결과가 같지않으면, Error 계산(출력층결과 - 지도데이터)\n",
        "2. 가중치수정\n",
        "W(t+1) = W - L*V*E\n",
        "L : Learning Rate\n",
        "V : 각 층의 값 \n",
        "E : Error\n",
        "3. 은닉층 값 / 출력층 값 계산\n",
        "1.6 = 2*0.4+1*0.8\n",
        "1.76 = 1.6*0.6+1*0.8\n",
        "4. 3에 의해 출력층 결과값 1.76 도출\n",
        " \n",
        "## (2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은? : \n",
        "* 학습율 0.1\n",
        "\n",
        "  * 학습률과 오차가 높을수록  가중치변화가 크다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgavfvqiWxBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}